# üìã ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠

> **‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠:** 2026-02-02  
> **‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå:** ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ï‡∏±‡∏ß‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Preprocessing

---

## üóÇÔ∏è ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î

```
RD_model_LST2/
‚îú‚îÄ‚îÄ üìä DATA COLLECTION
‚îÇ   ‚îú‚îÄ‚îÄ GEE_Export_Additional_Data.js    # Script ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Earth Engine
‚îÇ   ‚îî‚îÄ‚îÄ data/                            # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö GeoTIFF files
‚îÇ       ‚îú‚îÄ‚îÄ Monthly_LST_Filled_2018-2025.tif
‚îÇ       ‚îú‚îÄ‚îÄ Monthly_CH4_2018-2025.tif
‚îÇ       ‚îú‚îÄ‚îÄ Monthly_NO2_2018-2025.tif
‚îÇ       ‚îú‚îÄ‚îÄ Monthly_CO_2018-2025.tif
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ üîß PREPROCESSING & TRAINING
‚îÇ   ‚îú‚îÄ‚îÄ train_model_fast.py              # ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)
‚îÇ   ‚îú‚îÄ‚îÄ train_model_optimized.py         # ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏Å‡πâ Overfitting
‚îÇ   ‚îú‚îÄ‚îÄ train_model_final.py             # ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏ï‡∏±‡∏î LULC/DEM)
‚îÇ   ‚îî‚îÄ‚îÄ train_hybrid_model.py            # Hybrid Model (RF + DNN)
‚îÇ
‚îú‚îÄ‚îÄ üìà EVALUATION & ANALYSIS
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_model.py                # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÇ‡∏°‡πÄ‡∏î‡∏•
‚îÇ   ‚îú‚îÄ‚îÄ investigate_features.py          # ‡∏™‡∏∑‡∏ö‡∏™‡∏ß‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ LULC/DEM
‚îÇ   ‚îú‚îÄ‚îÄ create_heatmap.py                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Correlation Heatmap
‚îÇ   ‚îî‚îÄ‚îÄ test_model_stability.py          # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
‚îÇ
‚îú‚îÄ‚îÄ üì¶ OUTPUT FILES
‚îÇ   ‚îú‚îÄ‚îÄ df_final_processed.parquet       # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô preprocessing ‡πÅ‡∏•‡πâ‡∏ß
‚îÇ   ‚îú‚îÄ‚îÄ model_rf.joblib                  # Random Forest Model
‚îÇ   ‚îú‚îÄ‚îÄ model_dnn.joblib                 # Deep Neural Network Model
‚îÇ   ‚îú‚îÄ‚îÄ scaler.joblib                    # StandardScaler ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DNN
‚îÇ   ‚îî‚îÄ‚îÄ ensemble_weights.txt             # ‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å Ensemble
‚îÇ
‚îî‚îÄ‚îÄ üìÑ DOCUMENTATION
    ‚îî‚îÄ‚îÄ final_docs/                      # ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ß‡∏¥‡∏à‡∏±‡∏¢
        ‚îî‚îÄ‚îÄ thesis_combined.md           # ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏â‡∏ö‡∏±‡∏ö‡∏£‡∏ß‡∏°
```

---

## üéØ ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö Pipeline)

---

### 1Ô∏è‚É£ `GEE_Export_Additional_Data.js` - Data Collection

**‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á:** Root folder  
**‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Earth Engine

```javascript
// ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
var thailand = ee
  .FeatureCollection("USDOS/LSIB_SIMPLE/2017")
  .filter(ee.Filter.eq("country_na", "Thailand"));

var startDate = "2018-01-01";
var endDate = "2025-10-31";

// Export ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î 1 km
var exportParams = {
  scale: 1000, // 1 km resolution
  crs: "EPSG:4326",
};
```

**‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á:**
| ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• | ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ |
|------------|--------|
| Sentinel-5P | CH‚ÇÑ, NO‚ÇÇ, CO |
| MODIS | LST, NDVI, Albedo |
| ERA5 | Solar Radiation |

---

### 2Ô∏è‚É£ `train_hybrid_model.py` - Preprocessing & Training (‚≠ê ‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å)

**‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á:** Root folder  
**‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• + ‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

#### üìå ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô Preprocessing ‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î:

```python
# --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
df = pd.read_parquet('df_final_processed.parquet')

# --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Features ---
features = ['CH4', 'NO2', 'CO', 'NDVI', 'Albedo', 'Solar_Radiation', 'month', 'year']
# ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏ï‡∏±‡∏î LULC ‡πÅ‡∏•‡∏∞ DEM ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏£‡∏≤‡∏∞ Zero Variance

# --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: Imputation ---
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean')  # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
X = imputer.fit_transform(X)

# --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: Standardization (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DNN ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô) ---
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: Data Splitting ---
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y,
    test_size=0.3,      # 70% train, 30% test
    random_state=42     # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ
)
```

#### üìå ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:

```python
# --- Model 1: Random Forest ---
rf_model = RandomForestRegressor(
    n_estimators=100,      # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ
    max_depth=20,          # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting
    min_samples_split=20,  # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ö‡πà‡∏á node
    n_jobs=-1,             # ‡πÉ‡∏ä‡πâ CPU ‡∏ó‡∏∏‡∏Å core
    random_state=42
)

# --- Model 2: Deep Neural Network ---
dnn_model = MLPRegressor(
    hidden_layer_sizes=(128, 64, 32),  # 3 ‡∏ä‡∏±‡πâ‡∏ô: 128 -> 64 -> 32 neurons
    activation='relu',                  # ReLU activation function
    solver='adam',                      # Adam optimizer
    alpha=0.0001,                       # L2 regularization
    batch_size=64,
    max_iter=500,
    early_stopping=True                 # ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
)

# --- Ensemble: Weighted Average ---
w_rf = rf_r2 / (rf_r2 + dnn_r2)    # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏≤‡∏° R¬≤ score
w_dnn = dnn_r2 / (rf_r2 + dnn_r2)
y_pred_ensemble = (rf_pred * w_rf) + (dnn_pred * w_dnn)
```

---

### 3Ô∏è‚É£ `train_model_final.py` - Version ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (Random Forest Only)

**‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å hybrid:**

- ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Random Forest
- ‡∏°‡∏µ Cross-Validation (5-Fold)
- ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Overfitting Gap

```python
# Cross-Validation
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
print(f"CV R¬≤ Mean: {cv_scores.mean():.4f}")

# Overfitting Check
gap = r2_train - r2_test
if gap < 0.1:
    print("‚úì ‡∏î‡∏µ‡∏°‡∏≤‡∏Å! Overfitting ‡∏ô‡πâ‡∏≠‡∏¢")
```

---

### 4Ô∏è‚É£ `investigate_features.py` - ‡∏™‡∏∑‡∏ö‡∏™‡∏ß‡∏ô Zero Variance

**‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà:** ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏° LULC ‡πÅ‡∏•‡∏∞ DEM ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•

```python
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô
for feature in features:
    print(f"{feature}: Variance = {df[feature].var():.4f}")
    if df[feature].nunique() == 1:
        print(f"‚ö†Ô∏è WARNING: {feature} ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß!")

# ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö:
# LULC: Variance = 0.0000 (Zero Variance!)
# DEM: Variance = 0.0000 (Zero Variance!)
```

**‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡∏ó‡∏µ‡πà‡∏û‡∏ö:**

- ‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏° 30,000 ‡∏à‡∏∏‡∏î‡∏≠‡∏≤‡∏à‡πÑ‡∏î‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
- ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡∏π‡∏Å broadcast ‡πÉ‡∏´‡πâ‡∏°‡∏µ 94 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÅ‡∏ï‡πà‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô

---

### 5Ô∏è‚É£ `evaluate_model.py` - ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

```python
from sklearn.metrics import mean_squared_error, r2_score

# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤
y_pred = model.predict(X_test)

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"R¬≤: {r2:.4f}")     # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: 0.7130
print(f"RMSE: {rmse:.4f}") # ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: 2.04¬∞C
```

---

## üìä ‡∏™‡∏£‡∏∏‡∏õ Preprocessing Pipeline (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PREPROCESSING PIPELINE                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚ë† Data Collection (GEE)                                           ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sentinel-5P, MODIS, ERA5                         ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ 94 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (2018-2025)                                   ‚îÇ
‚îÇ                     ‚ñº                                               ‚îÇ
‚îÇ  ‚ë° Random Sampling                                                  ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ ‡∏™‡∏∏‡πà‡∏° 30,000 ‡∏à‡∏∏‡∏î‡∏†‡∏≤‡∏û ‚Üí 2.8 ‡∏•‡πâ‡∏≤‡∏ô‡πÅ‡∏ñ‡∏ß                           ‚îÇ
‚îÇ                     ‚ñº                                               ‚îÇ
‚îÇ  ‚ë¢ Missing Data Imputation                                         ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ SimpleImputer(strategy='mean')                             ‚îÇ
‚îÇ                     ‚ñº                                               ‚îÇ
‚îÇ  ‚ë£ Outlier Filtering                                               ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ ‡∏Å‡∏£‡∏≠‡∏á LST > 0 ‡∏≠‡∏á‡∏®‡∏≤ ‚Üí 984,274 ‡πÅ‡∏ñ‡∏ß                            ‚îÇ
‚îÇ                     ‚ñº                                               ‚îÇ
‚îÇ  ‚ë§ Feature Selection (Variance Thresholding)                       ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ ‡∏ï‡∏±‡∏î LULC, DEM (Zero Variance)                              ‚îÇ
‚îÇ                     ‚ñº                                               ‚îÇ
‚îÇ  ‚ë• Data Splitting                                                   ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ 70% Train / 30% Test                                       ‚îÇ
‚îÇ                     ‚ñº                                               ‚îÇ
‚îÇ  ‚ë¶ Standardization (for DNN only)                                  ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ StandardScaler: z = (x - Œº) / œÉ                            ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚ùì ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏≠‡∏≤‡∏à‡∏ñ‡∏≤‡∏° + ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö

### Q1: ‡∏ó‡∏≥‡πÑ‡∏°‡πÉ‡∏ä‡πâ Mean Imputation?

**A:**

- ‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏õ‡∏Å‡∏ï‡∏¥
- ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ö‡πâ
- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏°‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•

### Q2: ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏î LULC ‡πÅ‡∏•‡∏∞ DEM ‡∏≠‡∏≠‡∏Å?

**A:**

- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏°‡∏µ Variance = 0 (‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
- ‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
- ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡πÑ‡∏°‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

### Q3: ‡∏ó‡∏≥‡πÑ‡∏° StandardScaler ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö DNN ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö RF?

**A:**

- DNN ‡πÉ‡∏ä‡πâ Gradient Descent ‡∏ã‡∏∂‡πà‡∏á‡πÑ‡∏ß‡∏ï‡πà‡∏≠‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
- Random Forest ‡πÄ‡∏õ‡πá‡∏ô Tree-based ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô Scale-invariant (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö)

### Q4: 70/30 Split ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÑ‡∏´‡∏°?

**A:**

- ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
- ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô (688,991 ‡πÅ‡∏ñ‡∏ß) ‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö (295,283 ‡πÅ‡∏ñ‡∏ß)
- ‡πÉ‡∏ä‡πâ Cross-Validation (5-Fold) ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à

### Q5: Early Stopping ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?

**A:**

- ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤ Loss ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Epoch
- ‡∏´‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤ Loss ‡πÑ‡∏°‡πà‡∏•‡∏î‡∏•‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏≠‡∏ö ‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏™‡∏≠‡∏ô
- ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Overfitting ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Training ‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

---

## üîß ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå

```bash
# 1. ‡∏£‡∏±‡∏ô Training (Hybrid Model)
python train_hybrid_model.py

# 2. ‡∏£‡∏±‡∏ô Training (RF Final)
python train_model_final.py

# 3. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
python evaluate_model.py

# 4. ‡∏™‡∏∑‡∏ö‡∏™‡∏ß‡∏ô Features
python investigate_features.py
```

---

## üìÅ ‡πÑ‡∏ü‡∏•‡πå Output ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

| ‡πÑ‡∏ü‡∏•‡πå                         | ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢                     | ‡∏Ç‡∏ô‡∏≤‡∏î    |
| ---------------------------- | ---------------------------- | ------- |
| `df_final_processed.parquet` | ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô preprocessing  | ~38 MB  |
| `model_rf.joblib`            | ‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest          | ~400 MB |
| `model_dnn.joblib`           | ‡πÇ‡∏°‡πÄ‡∏î‡∏• Deep Neural Network    | ~285 KB |
| `scaler.joblib`              | StandardScaler parameters    | ~1 KB   |
| `ensemble_weights.txt`       | ‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å RF=0.55, DNN=0.45 | ~46 B   |

---‚ùì ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° 5 ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏≠‡∏≤‡∏à‡∏ñ‡∏≤‡∏°:
‡∏ó‡∏≥‡πÑ‡∏°‡πÉ‡∏ä‡πâ Mean Imputation?
‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏î LULC ‡πÅ‡∏•‡∏∞ DEM ‡∏≠‡∏≠‡∏Å?
‡∏ó‡∏≥‡πÑ‡∏° StandardScaler ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö DNN ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö RF?
70/30 Split ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÑ‡∏´‡∏°?
Early Stopping ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á?


