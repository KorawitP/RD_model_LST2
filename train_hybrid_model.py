# --- ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Hybrid (Random Forest + Deep Learning) ---
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import VotingRegressor
import time
import gc
import os

print("="*70)
print("=== Hybrid Model Training (RF + Deep Learning) ===")
print("=== Stacking Ensemble Approach ===")
print("="*70)

# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("\n[1/6] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
start_time = time.time()
if os.path.exists('df_final_processed.parquet'):
    df = pd.read_parquet('df_final_processed.parquet')
else:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå df_final_processed.parquet ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô train_model_final.py ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    exit()
    
print(f"‚úì ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß ({time.time()-start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

# 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features
features = ['CH4', 'NO2', 'CO', 'NDVI', 'Albedo', 'Solar_Radiation', 'month', 'year']
target = 'LST'
X = df[features].values
y = df[target].values.ravel()

del df
gc.collect()

# 3. Preprocessing (Imputation & Scaling)
print("\n[2/6] Preprocessing...")
# Imputation
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)

# Scaling (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Neural Network)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
print(f"‚úì ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: Train={len(X_train):,}, Test={len(X_test):,}")

# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
print("\n[3/6] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà)...")

# --- Model 1: Random Forest (Optimized) ---
print("   > Training Random Forest...")
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,  # ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß
    min_samples_split=20,
    n_jobs=-1,
    random_state=42
)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_r2 = r2_score(y_test, rf_pred)
print(f"     ‚úÖ RF Test R¬≤: {rf_r2:.4f}")

# --- Model 2: Deep Neural Network (DNN) ---
print("   > Training Deep Neural Network (DNN)...")
dnn_model = MLPRegressor(
    hidden_layer_sizes=(128, 64, 32), # 3 Hidden Layers
    activation='relu',
    solver='adam',
    alpha=0.0001,
    batch_size=64,
    learning_rate='adaptive',
    max_iter=500, # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ
    early_stopping=True,
    random_state=42
)
dnn_model.fit(X_train, y_train)
dnn_pred = dnn_model.predict(X_test)
dnn_r2 = r2_score(y_test, dnn_pred)
print(f"     ‚úÖ DNN Test R¬≤: {dnn_r2:.4f}")

# 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á Ensemble (Weighted Average)
print("\n[4/6] ‡∏™‡∏£‡πâ‡∏≤‡∏á Ensemble Model...")
# ‡πÉ‡∏´‡πâ‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏≤‡∏°‡∏Ñ‡πà‡∏≤ R2 (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏´‡∏ô‡πÅ‡∏°‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏¢‡∏≠‡∏∞‡∏Å‡∏ß‡πà‡∏≤)
total_score = rf_r2 + dnn_r2
w_rf = rf_r2 / total_score
w_dnn = dnn_r2 / total_score

print(f"   - Weights: RF={w_rf:.2f}, DNN={w_dnn:.2f}")

y_pred_ensemble = (rf_pred * w_rf) + (dnn_pred * w_dnn)
ensemble_r2 = r2_score(y_test, y_pred_ensemble)
ensemble_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))

# 6. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
print("\n" + "="*70)
print("=== FINAL RESULTS (Hybrid System) ===")
print("="*70)
print(f"1. Random Forest R¬≤ : {rf_r2:.4f}")
print(f"2. Deep Learning R¬≤ : {dnn_r2:.4f}")
print("-" * 30)
print(f"üèÜ Hybrid Ensemble R¬≤: {ensemble_r2:.4f}")
print(f"üìâ Hybrid Ensemble RMSE: {ensemble_rmse:.4f}")
print("="*70)

if ensemble_r2 > max(rf_r2, dnn_r2):
    print("‚ú® SUCCESS: ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß!")
else:
    print("‚ÑπÔ∏è Note: ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÅ‡∏ï‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ (Stability)")

# 7. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•
print("\n[6/6] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
joblib.dump(rf_model, 'model_rf.joblib')
joblib.dump(dnn_model, 'model_dnn.joblib')
joblib.dump(scaler, 'scaler.joblib')
# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å weights ‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
with open("ensemble_weights.txt", "w") as f:
    f.write(f"RF:{w_rf}\nDNN:{w_dnn}")
    
print("‚úì ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Scaler ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
print("üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£!")
