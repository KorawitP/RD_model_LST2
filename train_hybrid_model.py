# --- ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Hybrid (‡∏•‡∏π‡∏Å‡∏ú‡∏™‡∏° Random Forest + Deep Learning üß†üå≤) ---
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import time
import gc
import os

# ==============================================================================
# üìù ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà (Concept):
# ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏• "‡∏•‡∏π‡∏Å‡∏ú‡∏™‡∏°" (Hybrid / Ensemble) ‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏≠‡∏≤‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á 2 ‡πÇ‡∏•‡∏Å‡∏°‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô:
#
# 1. Random Forest (RF): ‡πÄ‡∏Å‡πà‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á, ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏¢‡∏≠‡∏∞, ‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô (Robust)
# 2. Deep Learning (DNN): ‡πÄ‡∏Å‡πà‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô, ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏•‡∏∂‡∏Å‡∏ã‡∏∂‡πâ‡∏á‡πÑ‡∏î‡πâ (Complex Patterns)
#
# ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Weighted Average Ensemble):
# - ‡πÉ‡∏´‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà‡∏•‡∏≠‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ä‡∏∏‡∏î
# - ‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà‡∏°‡∏≤ "‡∏ú‡∏™‡∏°‡∏Å‡∏±‡∏ô" ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å (Weighting)
# - ‡πÉ‡∏Ñ‡∏£‡πÄ‡∏Å‡πà‡∏á‡∏Å‡∏ß‡πà‡∏≤ (R¬≤ ‡πÄ‡∏¢‡∏≠‡∏∞‡∏Å‡∏ß‡πà‡∏≤) ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠‡πÄ‡∏¢‡∏≠‡∏∞‡∏Å‡∏ß‡πà‡∏≤
# - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏ö‡∏ö‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà
# ==============================================================================

print("="*70)
print("=== Hybrid Model Training (RF + Deep Learning) ===")
print("=== ‡∏£‡∏∞‡∏ö‡∏ö‡∏•‡∏π‡∏Å‡∏ú‡∏™‡∏°: ‡∏õ‡πà‡∏≤‡πÑ‡∏°‡πâ (RF) + ‡∏™‡∏°‡∏≠‡∏á‡∏Å‡∏• (Neural Network) ===")
print("="*70)

# ------------------------------------------------------------------------------
# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# ------------------------------------------------------------------------------
print("\n[1/6] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
start_time = time.time()
if os.path.exists('data/df_final_processed.parquet'):
    df = pd.read_parquet('data/df_final_processed.parquet')
else:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•! ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô train_model_final.py ‡∏Å‡πà‡∏≠‡∏ô")
    exit()
    
print(f"‚úì ‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß ({time.time()-start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

# ------------------------------------------------------------------------------
# 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features
# ------------------------------------------------------------------------------
features = ['CH4', 'NO2', 'CO', 'NDVI', 'Albedo', 'Solar_Radiation', 'month', 'year']
target = 'LST'

# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Numpy Array ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏≠‡∏á Neural Network
X = df[features].values
y = df[target].values.ravel()  # ravel() ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô array 1 ‡∏°‡∏¥‡∏ï‡∏¥

del df
gc.collect()

# ------------------------------------------------------------------------------
# 3. Preprocessing (‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á)
# ------------------------------------------------------------------------------
print("\n[2/6] Preprocessing (‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°)...")

# 3.1 Imputation (‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ)
print("   > Imputation: ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢")
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X)

# 3.2 Scaling (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Neural Network!)
# Deep Learning ‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏°‡∏µ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô 0.01 vs 1000)
# StandardScaler ‡∏à‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Å‡∏•‡∏≤‡∏á (z-score) ‡∏Ñ‡∏∑‡∏≠ Mean=0, Std=1
print("   > Scaling: ‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Deep Learning)")
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)
print(f"‚úì ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: Train={len(X_train):,}, Test={len(X_test):,}")

# ------------------------------------------------------------------------------
# 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (Training)
# ------------------------------------------------------------------------------
print("\n[3/6] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ)...")

# --- Model 1: Random Forest (RF) ---
print("\nüëâ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà 1: Random Forest (‡∏õ‡πà‡∏≤‡πÑ‡∏°‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à)")
print("   ...‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Random Forest...")
rf_model = RandomForestRegressor(
    n_estimators=100,      # üå≤ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ 100 ‡∏ï‡πâ‡∏ô
    max_depth=20,          # üìè ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 20 (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢)
    min_samples_split=20,  # ‚úÇÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ï‡∏Å‡∏Å‡∏¥‡πà‡∏á
    n_jobs=-1,             # ‚ö° ‡πÉ‡∏ä‡πâ CPU ‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà
    random_state=42
)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_r2 = r2_score(y_test, rf_pred)
print(f"   ‚úÖ RF Test Result (R¬≤): {rf_r2:.4f}")

# --- Model 2: Deep Neural Network (DNN) ---
print("\nüëâ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà 2: Deep Neural Network (‡∏™‡∏°‡∏≠‡∏á‡∏Å‡∏• Multi-Layer Perceptron)")
print("   ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á: Input -> 128 -> 64 -> 32 -> Output (3 Hidden Layers)")
print("   ...‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô DNN (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏≤‡∏ô‡∏Å‡∏ß‡πà‡∏≤ RF)...")

dnn_model = MLPRegressor(
    # üß† hidden_layer_sizes: ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏°‡∏≠‡∏á
    # (128, 64, 32) ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡∏°‡∏µ 3 ‡∏ä‡∏±‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î
    # ‡∏ä‡∏±‡πâ‡∏ô 1 ‡∏°‡∏µ 128 ‡πÄ‡∏ã‡∏•‡∏•‡πå -> ‡∏ä‡∏±‡πâ‡∏ô 2 ‡∏°‡∏µ 64 ‡πÄ‡∏ã‡∏•‡∏•‡πå -> ‡∏ä‡∏±‡πâ‡∏ô 3 ‡∏°‡∏µ 32 ‡πÄ‡∏ã‡∏•‡∏•‡πå (‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡∏Å‡∏•‡∏±‡πà‡∏ô‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
    hidden_layer_sizes=(128, 64, 32), 
    
    # ‚ö° activation: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Ñ‡∏¥‡∏î (Activation Function)
    # 'relu' (Rectified Linear Unit) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡∏ó‡∏¥‡πâ‡∏á
    activation='relu',
    
    # üõ†Ô∏è solver: ‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á (Optimizer)
    # 'adam' ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡πà‡∏á ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    solver='adam',
    
    # ü©π alpha: ‡∏Å‡∏≤‡∏£‡∏•‡∏á‡πÇ‡∏ó‡∏© (L2 Regularization)
    # 0.0001 ‡∏Ñ‡∏∑‡∏≠‡∏•‡∏á‡πÇ‡∏ó‡∏©‡πÄ‡∏ö‡∏≤‡πÜ ‡∏ñ‡πâ‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ (‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô Overfitting)
    alpha=0.0001,
    
    # üì¶ batch_size: ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠
    # ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡∏•‡∏∞ 64 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏µ‡∏ô‡∏∂‡∏á (‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏à‡∏≥‡πÅ‡∏°‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î)
    batch_size=64,
    
    # üîÑ Training Loop
    max_iter=500,        # ‡∏ß‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 500 ‡∏£‡∏≠‡∏ö
    early_stopping=True, # üõë ‡∏ñ‡πâ‡∏≤‡∏â‡∏•‡∏≤‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡∏Å‡∏±‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏ß‡∏•‡∏≤)
    
    random_state=42
)
dnn_model.fit(X_train, y_train)
dnn_pred = dnn_model.predict(X_test)
dnn_r2 = r2_score(y_test, dnn_pred)
print(f"   ‚úÖ DNN Test Result (R¬≤): {dnn_r2:.4f}")

# ------------------------------------------------------------------------------
# 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡∏°‡∏ú‡∏™‡∏° (Ensemble / Hybrid)
# ------------------------------------------------------------------------------
print("\n[4/6] ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡∏°‡∏ú‡∏™‡∏° (Hybrid Ensemble)...")
print("   ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£: ‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô R¬≤ ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å (‡πÉ‡∏Ñ‡∏£‡πÄ‡∏Å‡πà‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡∏Å‡∏ß‡πà‡∏≤)")

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å (Weights)
total_score = rf_r2 + dnn_r2
w_rf = rf_r2 / total_score     # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á RF
w_dnn = dnn_r2 / total_score   # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏≠‡∏á DNN

print(f"   ‚öñÔ∏è  ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ:")
print(f"       - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠ Random Forest: {w_rf*100:.2f}%")
print(f"       - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠ Deep Learning: {w_dnn*100:.2f}%")

# ‡∏£‡∏ß‡∏°‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (Weighted Average Prediction)
# ‡∏™‡∏π‡∏ï‡∏£: (‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏öRF * ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏ÅRF) + (‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏öDNN * ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏ÅDNN)
y_pred_ensemble = (rf_pred * w_rf) + (dnn_pred * w_dnn)

ensemble_r2 = r2_score(y_test, y_pred_ensemble)
ensemble_rmse = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))

# ------------------------------------------------------------------------------
# 6. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡∏°‡∏ú‡∏™‡∏°
# ------------------------------------------------------------------------------
print("\n" + "="*70)
print("=== üèÅ FINAL SCOREBOARD (‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô) ===")
print("="*70)
print(f"1. üå≤ Random Forest R¬≤ : {rf_r2:.4f}")
print(f"2. üß† Deep Learning R¬≤ : {dnn_r2:.4f}")
print("-" * 30)
print(f"üèÜ ü§ù Hybrid Ensemble R¬≤: {ensemble_r2:.4f} (‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡∏°‡∏ú‡∏™‡∏°)")
print(f"üìâ Hybrid Ensemble RMSE: +/- {ensemble_rmse:.4f} ‡∏≠‡∏á‡∏®‡∏≤")
print("="*70)

if ensemble_r2 > max(rf_r2, dnn_r2):
    print("‚ú® SUCCESS: ‡∏ó‡∏µ‡∏°‡∏ú‡∏™‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏ó‡∏≥! (Synergy Effect)")
else:
    print("‚ÑπÔ∏è Note: ‡∏ó‡∏µ‡∏°‡∏ú‡∏™‡∏°‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏û‡∏∏‡πà‡∏á‡∏õ‡∏£‡∏µ‡πä‡∏î‡∏Ç‡∏∂‡πâ‡∏ô")
    print("   ‡πÅ‡∏ï‡πà‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ñ‡∏∑‡∏≠ '‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£' (Stability) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î")

# ------------------------------------------------------------------------------
# 7. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•
# ------------------------------------------------------------------------------
print("\n[6/6] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î...")

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏¢‡∏Å‡∏ä‡∏¥‡πâ‡∏ô‡∏™‡πà‡∏ß‡∏ô
joblib.dump(rf_model, 'models/model_rf.joblib')
joblib.dump(dnn_model, 'models/model_dnn.joblib')
joblib.dump(scaler, 'models/scaler.joblib') # ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° Scaler! (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≠‡∏ô‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏à‡∏£‡∏¥‡∏á)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÉ‡∏™‡πà Text file ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏ï‡∏≠‡∏ô‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà
with open("ensemble_weights.txt", "w") as f:
    f.write(f"RF:{w_rf}\nDNN:{w_dnn}")
    
print("‚úì ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞ Scaler ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")
print("üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£!")
