# --- ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest (‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ - ‡∏•‡∏ö LULC ‡πÅ‡∏•‡∏∞ DEM) ---
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import time
import gc

print("="*70)
print("=== ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest (‡∏â‡∏ö‡∏±‡∏ö‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢) ===")
print("=== ‡∏•‡∏ö LULC ‡πÅ‡∏•‡∏∞ DEM ‡∏≠‡∏≠‡∏Å‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô ===")
print("="*70)

# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("\n[1/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
start_time = time.time()
df = pd.read_parquet('df_final_processed.parquet')
print(f"‚úì ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß ({time.time()-start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

# 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡πÅ‡∏•‡∏∞ target (‡∏•‡∏ö LULC ‡πÅ‡∏•‡∏∞ DEM)
print("\n[2/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
# ‡∏•‡∏ö LULC ‡πÅ‡∏•‡∏∞ DEM ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô
features = ['CH4', 'NO2', 'CO', 'NDVI', 'Albedo', 'Solar_Radiation', 'month', 'year']
target = 'LST'

print(f"‚úì Features ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ: {features}")
print(f"‚úì ‡∏•‡∏ö‡∏≠‡∏≠‡∏Å: LULC, DEM (‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô)")
print(f"‚úì Target: {target}")

X_raw = df[features].copy()
y = df[target].copy()
del df
gc.collect()

# 3. ‡∏ó‡∏≥ Imputation
print("\n[3/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥ Imputation...")
start_time = time.time()
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X_raw)
del X_raw
gc.collect()
print(f"‚úì Imputation ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ({time.time()-start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

# 4. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("\n[4/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
del X, y
gc.collect()
print(f"‚úì Train set: {len(X_train):,} ‡πÅ‡∏ñ‡∏ß")
print(f"‚úì Test set: {len(X_test):,} ‡πÅ‡∏ñ‡∏ß")

# 5. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
print("\n[5/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
print("‚ö° ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•:")
print("   - n_estimators=100")
print("   - max_depth=25")
print("   - min_samples_split=20")
print("   - min_samples_leaf=10")
print("   - max_features='sqrt'")
print("   - n_jobs=-1")
print("\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô...")

start_time = time.time()

model = RandomForestRegressor(
    n_estimators=100,
    max_depth=25,
    min_samples_split=20,
    min_samples_leaf=10,
    max_features='sqrt',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

model.fit(X_train, y_train)
training_time = time.time() - start_time

print(f"\n‚úì ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {training_time/60:.2f} ‡∏ô‡∏≤‡∏ó‡∏µ")

# 6. Cross-Validation
print("\n[6/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥ Cross-Validation (5-Fold)...")
cv_scores = cross_val_score(model, X_train, y_train, cv=5, 
                            scoring='r2', n_jobs=-1, verbose=0)
print(f"‚úì CV R¬≤ Scores: {cv_scores}")
print(f"‚úì CV R¬≤ Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

# 7. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
print("\n[7/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•...")
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

r2_train = r2_score(y_train, y_pred_train)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))

r2_test = r2_score(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

print("\n" + "="*70)
print("=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ===")
print("="*70)
print(f"Train Set:")
print(f"  R¬≤ Score: {r2_train:.4f}")
print(f"  RMSE: {rmse_train:.4f}")
print(f"\nTest Set:")
print(f"  R¬≤ Score: {r2_test:.4f}")
print(f"  RMSE: {rmse_test:.4f}")
print(f"\nCross-Validation (5-Fold):")
print(f"  R¬≤ Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
print(f"\nOverfitting Check:")
gap = r2_train - r2_test
print(f"  Gap (Train - Test): {gap:.4f}")
if gap < 0.1:
    print(f"  ‚úì ‡∏î‡∏µ‡∏°‡∏≤‡∏Å! Overfitting ‡∏ô‡πâ‡∏≠‡∏¢")
elif gap < 0.2:
    print(f"  ‚ö† ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á - ‡∏¢‡∏±‡∏á‡∏°‡∏µ Overfitting ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢")
else:
    print(f"  ‚úó ‡∏°‡∏µ Overfitting ‡∏°‡∏≤‡∏Å")
print("="*70)

# 8. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
print("\n[8/8] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
model_path = 'random_forest_model_final.joblib'
joblib.dump(model, model_path)
print(f"‚úì ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: {model_path}")

# ‡πÅ‡∏™‡∏î‡∏á Feature Importance
print("\n=== Feature Importance ===")
feature_importance = pd.DataFrame({
    'Feature': features,
    'Importance': model.feature_importances_
}).sort_values('Importance', ascending=False)
print(feature_importance.to_string(index=False))

print("\n" + "="*70)
print("=== ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î! ===")
print("="*70)
print(f"‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {training_time/60:.2f} ‡∏ô‡∏≤‡∏ó‡∏µ")
print(f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {model_path}")

print("\nüí° ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤:")
print(f"   - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ LULC/DEM: Test R¬≤=0.7111, Gap=0.0651")
print(f"   - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà (‡πÑ‡∏°‡πà‡∏°‡∏µ LULC/DEM): Test R¬≤={r2_test:.4f}, Gap={gap:.4f}")

if r2_test >= 0.7111:
    print("\n‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°!")
else:
    diff = 0.7111 - r2_test
    print(f"\n‚ö†Ô∏è ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà R¬≤ ‡∏•‡∏î‡∏•‡∏á {diff:.4f} ({diff/0.7111*100:.2f}%)")
    print("   ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ")
