# 3.4 สถาปัตยกรรมแบบจำลอง (Model Architecture)

การวิจัยนี้ใช้วิธีการผสมผสาน (Hybrid Approach) โดยพัฒนาแบบจำลอง 2 ประเภท เพื่อเปรียบเทียบประสิทธิภาพและดึงจุดเด่นของแต่ละเทคนิคมาใช้ ได้แก่ **Random Forest Regressor** (ตัวแทน Machine Learning) และ **Deep Neural Network (DNN)** (ตัวแทน Deep Learning)

### 3.4.1 แบบจำลอง Random Forest (Baseline Model)

เลือกใช้เป็นแบบจำลองหลักเนื่องจากความสามารถในการอธิบายผล (Interpretability) และจัดการข้อมูลที่มีความสัมพันธ์ไม่เป็นเชิงเส้นได้ดี

- **การตั้งค่าไฮเปอร์พารามิเตอร์ (Hyperparameters):**
  - `n_estimators`: 100
  - `max_depth`: 25
  - `min_samples_split`: 20
  - `min_samples_leaf`: 10
  - `max_features`: 'sqrt'
  - `random_state`: 42

### 3.4.2 แบบจำลอง Deep Learning (Deep Neural Network: DNN)

เพื่อเพิ่มขีดความสามารถในการเรียนรู้ความสัมพันธ์ที่ซับซ้อนแบบไม่เป็นเชิงเส้น (Non-linear) ผู้วิจัยได้พัฒนาแบบจำลอง **Deep Neural Network (DNN)** หรือโครงข่ายประสาทเทียมแบบหลายชั้น (Multi-layer Perceptron: MLP) ซึ่งมีความสามารถในการสกัดคุณลักษณะ (Feature Extraction) ได้ลึกซึ้งกว่า Machine Learning ทั่วไป

**โครงสร้างสถาปัตยกรรม (Network Architecture):**

1.  **Input Layer**: รับข้อมูลเข้า (Features = 8)
2.  **Hidden Layer 1**: จำนวน 128 Neurons (Activation = `relu`)
3.  **Hidden Layer 2**: จำนวน 64 Neurons (Activation = `relu`)
4.  **Hidden Layer 3**: จำนวน 32 Neurons (Activation = `relu`)
5.  **Output Layer**: จำนวน 1 Unit (ทำนายค่า LST)

**การตั้งค่าการฝึกสอน (Training Configuration):**

- **Algorithm**: Multi-layer Perceptron (MLPRegressor)
- **Optimizer**: Adam (Adaptive Learning Rate)
- **Loss Function**: Mean Squared Error (MSE)
- **Batch Size**: 64
- **Max Iterations**: 500 รอบ (Epochs)
- **Early Stopping**: หยุดการฝึกสอนเมื่อค่า Loss ไม่ลดลงเพื่อป้องกัน Overfitting

### 3.4.3 การผสานแบบจำลอง (Ensemble Strategy)

นอกจากการเปรียบเทียบผลลัพธ์ของทั้งสองแบบจำลองแยกกันแล้ว งานวิจัยนี้ยังประยุกต์ใช้เทคนิค **Weighted Averaging Ensemble** โดยนำค่าพยากรณ์จาก Random Forest และ Deep Neural Network มาหาค่าเฉลี่ยถ่วงน้ำหนักเพื่อสร้างผลลัพธ์สุดท้ายที่มีความเสถียรสูงสุด

**สูตรการคำนวณ Ensemble:**

$$\hat{y}_{ensemble} = w_{RF} \times \hat{y}_{RF} + w_{DNN} \times \hat{y}_{DNN}$$

โดยที่:

- $\hat{y}_{ensemble}$ คือ ค่าพยากรณ์ LST จากแบบจำลอง Ensemble
- $\hat{y}_{RF}$ คือ ค่าพยากรณ์ LST จาก Random Forest
- $\hat{y}_{DNN}$ คือ ค่าพยากรณ์ LST จาก Deep Neural Network
- $w_{RF} = 0.55$ และ $w_{DNN} = 0.45$ คือ น้ำหนักของแต่ละแบบจำลอง (โดยที่ $w_{RF} + w_{DNN} = 1$)

**การกำหนดค่าน้ำหนัก:**

ค่าน้ำหนักถูกกำหนดตามสัดส่วนของค่าความแม่นยำ ($R^2$) ที่แต่ละแบบจำลองได้รับจากการ Cross-Validation เนื่องจาก Random Forest ให้ค่า $R^2$ ที่สูงกว่าจึงได้รับน้ำหนักที่มากกว่า อย่างไรก็ตาม การรวม DNN เข้ามาช่วยลดความแปรปรวน (Variance) และเพิ่มความเสถียรของการทำนายในข้อมูลที่ไม่เคยเห็นมาก่อน (Unseen Data)

### 3.4.4 ขั้นตอนการฝึกสอนแบบจำลอง (Training Pipeline)

กระบวนการฝึกสอนแบบจำลองดำเนินการตามขั้นตอนดังนี้:

1. **การแบ่งข้อมูล (Data Splitting):** แบ่งชุดข้อมูลออกเป็น 2 ส่วน ได้แก่ ชุดข้อมูลฝึกสอน (Training Set) ร้อยละ 70 และชุดข้อมูลทดสอบ (Testing Set) ร้อยละ 30 โดยใช้วิธีสุ่มแบบแบ่งชั้น (Stratified Sampling) ตามตัวแปรเวลา (Month)

2. **การปรับมาตรฐานข้อมูล (Standardization):** ใช้ StandardScaler เพื่อปรับค่าตัวแปรทั้งหมดให้มีค่าเฉลี่ยเท่ากับ 0 และส่วนเบี่ยงเบนมาตรฐานเท่ากับ 1 สำหรับแบบจำลอง DNN

3. **การฝึกสอน (Training):** ฝึกสอนทั้ง Random Forest และ DNN ด้วยชุดข้อมูลฝึกสอนเดียวกัน

4. **การตรวจสอบความถูกต้อง (Validation):** ใช้วิธี K-Fold Cross-Validation (k=5) เพื่อประเมินความสามารถในการทำนายและป้องกันปัญหา Overfitting

5. **การประเมินผล (Evaluation):** ทดสอบแบบจำลองกับชุดข้อมูลทดสอบและคำนวณค่าตัวชี้วัดประสิทธิภาพ
