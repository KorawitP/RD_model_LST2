# --- ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest (‡πÅ‡∏Å‡πâ Overfitting) ---
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import time
import gc

print("="*60)
print("=== ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest (‡πÅ‡∏Å‡πâ Overfitting) ===")
print("="*60)

# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("\n[1/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
start_time = time.time()
df = pd.read_parquet('df_final_processed.parquet')
print(f"‚úì ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df):,} ‡πÅ‡∏ñ‡∏ß ({time.time()-start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

# 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° features ‡πÅ‡∏•‡∏∞ target
print("\n[2/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
features = ['CH4', 'NO2', 'CO', 'LULC', 'DEM', 'NDVI', 'Albedo', 'Solar_Radiation', 'month', 'year']
target = 'LST'

X_raw = df[features].copy()
y = df[target].copy()
del df
gc.collect()
print(f"‚úì Features: {len(features)} ‡∏ï‡∏±‡∏ß")
print(f"‚úì Target: {target}")

# 3. ‡∏ó‡∏≥ Imputation
print("\n[3/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥ Imputation...")
start_time = time.time()
imputer = SimpleImputer(strategy='mean')
X = imputer.fit_transform(X_raw)
del X_raw
gc.collect()
print(f"‚úì Imputation ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ({time.time()-start_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)")

# 4. ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print("\n[4/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
del X, y
gc.collect()
print(f"‚úì Train set: {len(X_train):,} ‡πÅ‡∏ñ‡∏ß")
print(f"‚úì Test set: {len(X_test):,} ‡πÅ‡∏ñ‡∏ß")

# 5. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÉ‡∏ä‡πâ Regularization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ Overfitting)
print("\n[5/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
print("‚ö° ‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÅ‡∏Å‡πâ Overfitting:")
print("   - n_estimators=100 (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)")
print("   - max_depth=25 (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å)")
print("   - min_samples_split=20 (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥)")
print("   - min_samples_leaf=10 (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏ö)")
print("   - max_features='sqrt' (‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô features ‡∏ï‡πà‡∏≠ tree)")
print("   - n_jobs=-1 (‡πÉ‡∏ä‡πâ CPU ‡∏ó‡∏∏‡∏Å core)")
print("\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô... (‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤ 5-10 ‡∏ô‡∏≤‡∏ó‡∏µ)")

start_time = time.time()

model = RandomForestRegressor(
    n_estimators=100,         # ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°
    max_depth=25,             # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting)
    min_samples_split=20,     # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 20 samples ‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡πÅ‡∏ö‡πà‡∏á
    min_samples_leaf=10,      # ‡πÉ‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 10 samples
    max_features='sqrt',      # ‡πÉ‡∏ä‡πâ sqrt(n_features) ‡∏ï‡πà‡∏≠ tree
    n_jobs=-1,                # ‡πÉ‡∏ä‡πâ CPU ‡∏ó‡∏∏‡∏Å core
    random_state=42,
    verbose=1
)

model.fit(X_train, y_train)
training_time = time.time() - start_time

print(f"\n‚úì ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {training_time/60:.2f} ‡∏ô‡∏≤‡∏ó‡∏µ")

# 6. Cross-Validation
print("\n[6/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥ Cross-Validation (5-Fold)...")
print("‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà...")
cv_scores = cross_val_score(model, X_train, y_train, cv=5, 
                            scoring='r2', n_jobs=-1, verbose=0)
print(f"‚úì CV R¬≤ Scores: {cv_scores}")
print(f"‚úì CV R¬≤ Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

# 7. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•
print("\n[7/7] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•...")
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

r2_train = r2_score(y_train, y_pred_train)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))

r2_test = r2_score(y_test, y_pred_test)
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

print("\n" + "="*60)
print("=== ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ===")
print("="*60)
print(f"Train Set:")
print(f"  R¬≤ Score: {r2_train:.4f}")
print(f"  RMSE: {rmse_train:.4f}")
print(f"\nTest Set:")
print(f"  R¬≤ Score: {r2_test:.4f}")
print(f"  RMSE: {rmse_test:.4f}")
print(f"\nCross-Validation (5-Fold):")
print(f"  R¬≤ Mean: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
print(f"\nOverfitting Check:")
gap = r2_train - r2_test
print(f"  Gap (Train - Test): {gap:.4f}")
if gap < 0.1:
    print(f"  ‚úì ‡∏î‡∏µ‡∏°‡∏≤‡∏Å! Overfitting ‡∏ô‡πâ‡∏≠‡∏¢")
elif gap < 0.2:
    print(f"  ‚ö† ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á - ‡∏¢‡∏±‡∏á‡∏°‡∏µ Overfitting ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢")
else:
    print(f"  ‚úó ‡∏°‡∏µ Overfitting ‡∏°‡∏≤‡∏Å - ‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
print("="*60)

# 8. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
print("\n[8/8] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•...")
model_path = 'random_forest_model_optimized.joblib'
joblib.dump(model, model_path)
print(f"‚úì ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: {model_path}")

# ‡πÅ‡∏™‡∏î‡∏á Feature Importance
print("\n=== Feature Importance (Top 10) ===")
feature_importance = pd.DataFrame({
    'Feature': features,
    'Importance': model.feature_importances_
}).sort_values('Importance', ascending=False)
print(feature_importance.to_string(index=False))

print("\n" + "="*60)
print("=== ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î! ===")
print("="*60)
print(f"‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {training_time/60:.2f} ‡∏ô‡∏≤‡∏ó‡∏µ")
print(f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {model_path}")
print("\nüí° ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°:")
print(f"   - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏¥‡∏°: Train R¬≤=0.9601, Test R¬≤=0.7180 (Gap=0.2421)")
print(f"   - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà: Train R¬≤={r2_train:.4f}, Test R¬≤={r2_test:.4f} (Gap={gap:.4f})")
